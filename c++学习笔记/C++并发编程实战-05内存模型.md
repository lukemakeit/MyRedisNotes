## C++并发编程实战五: 内存模型

原文文档:

[C++11中的内存模型上篇 - 内存模型基础](https://www.codedump.info/post/20191214-cxx11-memory-model-1/)

[C++11中的内存模型下篇 - C++11支持的几种内存模型](https://www.codedump.info/post/20191214-cxx11-memory-model-2/)

[理解 C++ 的 Memory Order](http://senlinzhan.github.io/2017/12/04/cpp-memory-order/)

[如何理解 C++11 的六种 memory order?](https://www.zhihu.com/question/24301047)

![image-20211206204053666](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206204053666.png)

- 有多个CPU处理器，每个CPU处理器内部又有多个核心。
- 存在只能被一个CPU核心访问的L1 cache。
- 存在只能被一个CPU处理器的多个核心访问的L2 cache。
- 存在能被所有CPU处理器都能访问到的L3 cache以及内存。
- L1 cache、L2 cache、L3 cache的容量空间依次变大，但是访问速度依次变慢。

当CPU结构发生变化，增加了只能由内部才能访问的缓存之后，一些在旧架构上不会出现的问题，在新的架构上就会出现。而本篇的主角内存模型（memory model），其作用就是规定了各种不同的访问共享内存的方式，不同的内存模型，既需要编译器的支持，也需要硬件CPU的支持。

#### 简单的多线程访问数据问题

假设在程序执行之前，A=B=0，有两个线程同时分别执行如下的代码：

| 线程1       | 线程2       |
| ----------- | ----------- |
| 1. A=1      | 3. B=2      |
| 2. print(B) | 4. print(A) |

上述程序的执行结果如何？执行步骤不同可能导致的结果如下:

- 1->2->3->4, 则结果是(0,1);
- 3->4->1->2, 则结果是(0,2);
- 1->3->2->4, 则结果是(2,1);
- 1->3->4->2, 则结果是(1,2);

还有3-1->4->2和3->1->2-4 等等情况。

**不可能出现的情况**

除了以上的情况之外，还有一种可能是输出(0,0)，但是这种输出在一般情况下不可能出现。

![image-20211206210855138](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206210855138.png)

如果需要确保输出(0,0)。那么就: 4 happen-before 1 , 2  happen before 3。

但是**一个处理器内**的执行顺序，需按照程序顺序(program order)，因此需要保证 1 happen before 2， 3 happen before 4。

这四个条件是无法同时满足的。

#### Sequential Consistency(顺序一致性）

顺序一致性内存模型（Sequential Consistency）以下简称SC，由Lamport提出，其严格定义是：

> “… the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.”

简要来说对程序的执行结果有两个要求：

- 每个处理器的执行顺序和代码中的顺序（program order）一样;
- 所有处理器上的操作 都以某种顺序 执行完成，执行结果都是一样的。

我们以IM中的群聊消息作为例子说明顺序一致性的这两个要求。在这个例子中，群聊中的每个成员，相当于多核编程中的一个处理器，那么对照顺序一致性的两个要求就是：

- 每个人自己发出去的消息，必然是和ta说话的顺序一致的。即用户A在群聊中依次说了消息1和消息2，在群聊天的时候也必然是先看到消息1然后再看到消息2，这就是前面顺序一致性的第一个要求。
- 群聊中有多个用户参与聊天（多处理器），如果所有人看到的消息顺序都一样，那么就满足了前面顺序一致性的第二个要求了，但是这个顺序首先不能违背前面的第一个要求。

**顺序一致性的缺点**

顺序一致性实际上是一种强一致性，可以想象成整个程序过程中由一个开关来选择执行的线程，这样才能同时保证顺序一致性的两个条件。

实际上还是相当于同一时间只有一个线程在工作，简直和串行化差不多？

![image-20211206231641307](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206231641307.png)

#### 全存储排序(Total Store Ordering,简称 TSO)

有一些CPU架构，在处理核心中增加写缓存，一个写操作只要写入到本核心的写缓存中就可以返回，此时的CPU结构如图所示（图中并没有画出三级cache）：

![image-20211206231853663](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206231853663.png)

在这种结构下，SC所不允许的一些操作可能会出现。

还是以前面分析SC的程序例子来说明：

| 线程1       | 线程2       |
| ----------- | ----------- |
| 1. A=1      | 3. B=2      |
| 2. print(B) | 4. print(A) |

在新的CPU架构下，写一个值可能值写到本核心的缓冲区中就返回了，接着执行下面的一条指令，因此可能出现以下的情况：

![image-20211206232204899](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206232204899.png)

- 执行操作1，core 1写入A的新值1到core 1的缓冲区中之后就马上返回了，还并没有更新到所有CPU都能访问到的内存中。
- 执行操作3，core 2写入B的新值2到core 2的缓冲区中之后就马上返回了，还并没有更新到所有CPU都能访问到的内存中。
- 执行操作2，由于操作2访问到本core缓冲区中存储的B值还是原来的0，因此输出0。
- 执行操作4，由于操作4访问到本core缓冲区中存储的A值还是原来的0，因此输出0

可以看到，在引入了只能由每个core才能访问到的写缓冲区之后，之前SC中不可能出现的输出(0,0)的情况在这样的条件下可能出现了。

#### 松弛内存模型(Relaxed memory models)

以上已经介绍了两种内存模型，SC是最简单直白的内存模型，TSO在SC的基础上，加入了写缓存，写缓存的加入导致了一些在SC条件下不可能出现的情况也成为了可能。

然而，即便如此，以上两种内存模型**都没有改变单线程执行一个程序时的执行顺序**。在这里要讲的**松弛型内存模型，则改变了单线程执行一个程序的执行顺序**。

在松散型的内存模型中，编译器可以在满足程序单线程执行结果的情况下进行重排序（reorder），来看下面的程序：

```cpp
int A, B;
void foo() {
  A = B + 1;
  B = 0;
}
int main() {
  foo();
  return 0;
}
```

如果在不使用优化的情况下编译，gcc foo.c -S，foo函数中针对A和B操作的汇编代码如下：

```assembly
movl    B(%rip), %eax
addl    $1, %eax
movl    %eax, A(%rip)
movl    $0, B(%rip)
```

先把变量B的值赋给寄存器eax，将寄存器eax加一的结果赋值给变量A，最后再将变量B置为0。

如果使用O2优化编译，gcc foo.c -S -O2 则得到下面的汇编代码：

```assembly
movl    B(%rip), %eax
movl    $0, B(%rip)
addl    $1, %eax
movl    %eax, A(%rip)
```

先把变量B的值赋给寄存器eax，然后变量B置零，再将寄存器eax加一的结果赋值给变量A。

其原因在于，foo函数中，只要将变量B的值暂存下来，那么对变量B的赋值操作可以被打乱而并不影响程序的执行结果，这就是编译器可以做的重排序优化。

回到前面的例子中，在松弛型内存模型中，程序的执行顺序就不见得和代码中编写的一样了，这是这种内存模型和SC、TSO模型最大的差异。

以IM群聊消息为例子说明这个问题。假设有多人在群里聊天，如果A说的消息1与B说的消息2之间，没用明确的先后顺序，比如消息1是回复或者引用了消息2的话，那么其实在整个群聊视图里面，两者的先后顺序如何是无关紧要的。即参与群聊的两个用户，其中一个用户可能看到消息1在消息2之前，另一个用户看到的顺序相反，这都是无关大局的，因为两个消息之间没有关系。

#### sequenced-before

sequenced-before用于表示**<mark style="color:red;">单线程</mark>**之间，两个操作上的先后顺序，这个顺序是非对称、可以进行传递的关系。

它不仅仅表示两个操作之间的先后顺序，还表示了操作结果之间的可见性关系。两个操作A和操作B，如果有A sequenced-before B，除了表示操作A的顺序在B之前，还表示了操作A的结果操作B可见。

#### happens-before

与sequenced-before不同的是，happens-before关系表示的**<mark style="color:red;">不同线程</mark>**之间的操作先后顺序，同样的也是非对称、可传递的关系。

如果A happens-before B，则A的内存状态将在B操作执行之前就可见。前面某些情况下一个写操作只是简单的写入内存就返回了，其他核心上的操作不一定能马上见到操作的结果，这样的关系是不满足happens-before的。

#### synchronizes-with

synchronizes-with关系强调的是变量被修改之后的传播关系（propagate），即**如果一个线程修改某变量的之后的结果能被其它线程可见，那么就是满足synchronizes-with关系的**。

显然，满足synchronizes-with关系的操作一定满足happens-before关系了。

### C++11支持的内存模型

```cpp
enum memory_order {
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
};
```

![image-20211206234814698](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206234814698.png)

#### memory_order_seq_cst

默认的内存模型，即上篇文章中分析过的顺序一致性内存模型。

```cpp
#include <atomic>
#include <thread>
#include <assert.h>
std::atomic<bool> x,y;
std::atomic<int> z;
void write_x()
{
    x.store(true,std::memory_order_seq_cst);
}
void write_y()
{
    y.store(true,std::memory_order_seq_cst);
}
void read_x_then_y()
{
    while(!x.load(std::memory_order_seq_cst)); //退出循环,必然是write_x()已经执行完成,x==true
    if(y.load(std::memory_order_seq_cst)) //如果此时y==false,那么 read_y_then_x()必然还在不断的while循环
        ++z;
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_seq_cst));//退出循环,必然是write_y()已经执行完成,y==true
    if(x.load(std::memory_order_seq_cst)) //如果此时x==false,那么 read_x_then_y()必然还在不断的while循环
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join();
    b.join();
    c.join();
    d.join();
    assert(z.load()!=0);
}
```

由于采用了顺序一致性模型，因此最后的断言不可能发生，即在程序结束时不可能出现z为0的情况。

#### memory_order_relaxed

这种类型对应的松散内存模型，这种内存模型的特点是：

- 针对一个变量的读写操作是原子操作；
- 不同线程之间针对该变量的访问操作先后顺序不能得到保证，即有可能乱序。

```cpp
#include <atomic>
#include <thread>
#include <assert.h>
std::atomic<bool> x,y;
std::atomic<int> z;
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed); //1
    y.store(true,std::memory_order_relaxed); //2
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed)); //3
    if(x.load(std::memory_order_relaxed)) //4
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);
}
```

对原子变量的访问都使用memory_order_relaxed模型，1 和 2 没啥关系在同一个线程，3 和 4没啥关系在同一个线程。可能会先执行 `2->3->4->1` 或 `4->1->2->3`，那么此时最后断言都可能失败。z可能等于0。

#### Acquire-Release

- **memory_order_release**: 用来修饰一个写(store)操作, 表示本线程中，在`store()`之前的所有读写操作，不允许移动到这个`store()`的后面;
- **memory_order_acquire**: 用来修饰一个读(load)操作，表示本线程中，在`load()`之后的所有读写操作，不允许被移动到这个`load()`前面;
- **memory_order_acq_rel**：同时包含memory_order_acquire和memory_order_release标
- 简单记忆就是: `release`->写，`acquire`->读，`store`->`before`、`load`->`after`。

示例一:

```cpp
#include <thread>
#include <atomic>
#include <cassert>
#include <string>
std::atomic<bool> ready{ false };
int data = 0;
void producer()
{
    data = 100;                                       // A
    ready.store(true, std::memory_order_release);     // B
}
void consumer()
{
    while (!ready.load(std::memory_order_acquire))    // C
        ;
    assert(data == 100); // never failed              // D
}
int main()
{
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join();
    t2.join();
    return 0;
}
```

- 首先 A 不允许被移动到 B 的后面。
- 同样 D 也不允许被移动到 C 的前面。
- 当 C 从 while 循环中退出了，说明 C 读取到了 B `store()`的那个值，此时，Thread-2 保证能够看见 Thread-1 执行 B 之前的所有写入操作（也即是 A）

示例二:

```cpp
#include <atomic>
#include <thread>
#include <assert.h>
std::atomic<bool> x,y;
std::atomic<int> z;
void write_x_then_y()
{
    x.store(true,std::memory_order_relaxed); //A
    y.store(true,std::memory_order_release); //B
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_acquire)); //C
    if(x.load(std::memory_order_relaxed)) //D
        ++z;
}
int main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0);
}
```

- 首先 A 不允许被移动到 B 的后面。
- 同样 D 也不允许被移动到 C 的前面。
- 当 C 从 while 循环中退出了，说明 C 读取到了 B `store()`的那个值，此时，Thread-2 保证能够看见 Thread-1 执行 B 之前的所有写入操作（也即是 A）

针对同一个变量的release-acquire操作，更多时候扮演了一种“线程间使用某一变量的同步”作用，由于有了这个语义的保证，做到了线程间操作的先后顺序保证（inter-thread happens-before）。

#### Release-Consume

从上面对Acquire-Release模型的分析可以知道，虽然可以使用这个模型做到两个线程之间某些操作的synchronizes-with关系，然后这个粒度有些过于大了。

在很多时候，线程间只想针对有依赖关系的操作进行同步，除此之外线程中的其他操作顺序如何无所谓。比如下面的代码中：

```cpp
b = *a;
c = *b;
```

**其中第二行代码的执行结果依赖于第一行代码的执行结果，此时称这两行代码之间的关系为“carry-a-dependency ”**。

**C++中引入的memory_order_consume内存模型就针对这类代码间有明确的依赖关系的语句限制其先后顺序**。

示例:

```cpp
#include <string>
#include <thread>
#include <atomic>
#include <assert.h>
struct X
{
    int i;
    std::string s;
};
std::atomic<X*> p;
std::atomic<int> a;
void create_x()
{
    X* x=new X;
    x->i=42;
    x->s="hello";
    a.store(99,std::memory_order_relaxed); //A
    p.store(x,std::memory_order_release); //B
}
void use_x()
{
    X* x;
    while(!(x=p.load(std::memory_order_consume))) //C
        std::this_thread::sleep_for(std::chrono::microseconds(1));
    assert(x->i==42);
    assert(x->s=="hello");
    assert(a.load(std::memory_order_relaxed)==99); //D
}
int main()
{
    std::thread t1(create_x);
    std::thread t2(use_x);
    t1.join();
    t2.join();
}
```

- C使用memory_order_consume内存模型执行load操作，退出循环时，B必然已经发生;
- B使用memory_order_release内存模型，其前面的`x->i=42` 以及A 必然已经发生，所以`assert(x->i==42`、`assert(x->s=="hello")`肯定成功;
- 但是对于D来说，D和C没啥依赖关系。就有可能出现  D->A->B->C，那么此时D就可能失败。



#### 内存栅栏(memory barrier)

由于有了缓冲区的出现，导致一些操作不用到内存就可以返回继续执行后面的操作，为了保证某些操作必须是写入到内存之后才执行，就引入了内存栅栏（memory barrier，又称为memory fence）操作。内存栅栏指令保证了，在这条指令之前所有的内存操作的结果，都在这个指令之后的内存操作指令被执行之前，写入到内存中。也可以换另外的角度来理解内存栅栏指令的作用：显式的在程序的某些执行点上保证SC。

![image-20211206233231369](https://my-typora-pictures-1252258460.cos.ap-guangzhou.myqcloud.com/img/image-20211206233231369.png)

再次以前面的例子来说明这个指令，在X64下面，内存屏障指令使用汇编指令`asm volatile ("pause" ::: "memory");`来实现，如果将这个指令放到两个赋值语句之间：

```cpp
int A, B;
void foo()
{
    A = B + 1;
    asm volatile ("pause" ::: "memory");
    B = 0;
}
int main() {
  foo();
  return 0;
}
```

那么再次使用O2编译出来的汇编代码就变成了：

```assembly
.LFB1:
  .cfi_startproc
  movl  B(%rip), %eax
  addl  $1, %eax
  movl  %eax, A(%rip)
#APP
# 6 "foo.c" 1
  pause
# 0 "" 2
#NO_APP
  movl  $0, B(%rip)
```

可以看到，插入内存屏障指令之后，生成的汇编代码顺序就不会乱序了。

示例:

```cpp
#include <atomic>
#include <thread>
#include <assert.h>
std::atomic<bool> x,y;
std::atomic<int> z;
void write_x_then_y()
{
  x.store(true,std::memory_order_relaxed);  // 1
  std::atomic_thread_fence(std::memory_order_release);  // 2
  y.store(true,std::memory_order_relaxed);  // 3
}
void read_y_then_x()
{
  while(!y.load(std::memory_order_relaxed));  // 4
  std::atomic_thread_fence(std::memory_order_acquire);  // 5
  if(x.load(std::memory_order_relaxed))  // 6
    ++z;
}
int main()
{
  x=false;
  y=false;
  z=0;
  std::thread a(write_x_then_y);
  std::thread b(read_y_then_x);
  a.join();
  b.join();
  assert(z.load()!=0);  // 7
}
```

- 尽管 1 3 4 6都是memory_order_acquire内存模型；
- 不过 2 保证了  1 必须在 3之前执行； 5保证了 4 必须在 6之前执行；
- 2 释放栅栏后，5获得了栅栏。
- 最后的z肯定不会等于0，断言不会触发。
- 2 中释放栅栏的效果好像 对y的存储标记为`memory_order_release`，而不是`memory_order_relaxed`。5 获得栅栏就好像想给load y的操作4 标记为`memory_order_acquire



### 一个补充回答，记录一下

作者：文礼
链接：https://www.zhihu.com/question/24301047/answer/1193956492
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



**这个问题的难点在于，很多人以为它们是限制多线程之间的执行顺序**（包括我写这篇回答时的最高赞回答看起来也是这么认为的），**然而其实不是**。

事实上，[Sequentially-consistent ordering](https://www.zhihu.com/search?q=Sequentially-consistent+ordering&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1193956492})是目前绝大多数编译器的缺省设置。如果按照高赞回答的意思，那么多线程如果使用了atom操作，貌似就几乎变成了单线程（或者[回合制](https://www.zhihu.com/search?q=回合制&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1193956492})）？真的吗？

既然是多线程，那么线程之间的执行顺序就一定不是确定性的（你只能在某些点同步它们，但是在任何其它的地方是没有办法保证执行顺序的）。

C++11所规定的这6种模式，其实并不是限制（或者规定）两个线程该怎样同步执行，**而是在规定一个线程内的指令该怎样执行**。

是的，我知道这部分的文档（规定）以及给出的例子里面，满屏都是多线程。但是其实讨论的是单线程的问题。**更为准确地说，是在讨论单线程内的指令执行顺序对于多线程的影响的问题**。

首先，什么是原子操作？原子操作就是对一个内存上变量（或者叫左值）的读取-变更-存储（load-add-store）作为一个整体一次完成。

让我们考察一下普通的非原子操作：

`x++`

这个表达式如果编译成汇编，对应的是3条指令：

mov（从内存到寄存器），add，mov（从寄存器到内存）

那么在多线程环境下，就存在这样的可能：当线程A刚刚执行完第二条指令的时候，线程B开始执行第一条指令。那么就会导致线程B没有看到线程A执行的结果。如果这个变量初始值是0，那么线程A和线程B的结果都是1。

如果我们想要避免这种情况，就可以使用原子操作。使用了原子操作之后，你可以认为这3条指令变成了一个整体，从而别的线程无法在其执行的期间当中访问x。也就是起到了锁的作用。

所以，atom本身就是一种锁。它自己就已经完成了线程间同步的问题。这里并没有那6个memory order的什么事情。

问题在于以这个原子操作为中心，其前后的代码。这些代码并不一定需要是原子操作，只是普通的代码就行。

什么问题？比如还有另外一个变量y，在我们这个原子操作代码的附近，有一个

`y++`

那么现在的问题是，这个y++到底会在我们的x++之前执行，还是之后？

注意这完全是单线程当中指令的执行顺序问题，与多线程风马牛不相及。但是，这个问题会导致多线程执行结果的不同。理解了这个，就理解了那6种memory order。

为啥？因为我们对x进行原子操作的地方，锁定了线程间的关系，是一个同步点。那么，以这个点为基准，我们就可以得出两个线程当中其它指令执行先后顺序关系。

**比如，A线程先对x进行了自增操作。因为对x的访问是原子的，所以B线程执行该行代码（假设代码当中对x的访问只有这一处）的时间点必然在A完成之后**。

**那么，如果在A线程当中，y++是在x++之前执行的，那么我们就可以肯定，对于B线程来说，在x++（同步点）之后所有对y的参照，必定能看到A线程执行了y++之后的值（注意对y的访问并非原子）**

**但是有个问题。如果在程序当中y++紧靠x++，那么其实它到底是会先于x++执行（完毕），还是晚于x++执行（完毕），这个是没准儿的**。

为啥呢？首先编译器对代码可能进行指令重排。也就是说，编译器编译之后（特别是开了优化之后）的代码执行顺序，是不一定严格按照你写代码的顺序的。

但是如果仅仅如此，也只是二进制（机器码）的顺序与源代码不同，还不至于导致A和B当中的指令执行顺序不同（因为A和B执行的是相同的机器码程序）。但是实际上，在非常微观的层面上，A和B也是可能不同的，甚至于，A每次执行到这里顺序都不见得一样。

啥？...还真的是这样。**原因在于当代CPU内部也有指令重排。也就是说，CPU执行指令的顺序，也不见得是完全严格按照机器码的顺序。特别是，当代CPU的IPC（每时钟执行指令数）一般都远大于1，也就是所谓的多发射，很多命令都是同时执行的。比如，当代CPU当中（一个核心）一般会有2套以上的整数ALU（加法器），2套以上的浮点ALU（加法器），往往还有独立的乘法器，以及，独立的Load和Store执行器。Load和Store模块往往还有8个以上的队列，也就是可以同时进行8个以上内存地址（cache line）的读写交换**。

是不是有些晕？简单来说，你可以理解**当代CPU不仅是多核心，而且每个核心还是多任务（多指令）并行的**。计算机课本上的那种一个时钟一条指令的，早就是老黄历了 （当然，宏观来看基本原理并没有改变）

看到这里还没有晕的话，那么恭喜你，你快要理解什么是memory order了。<mark style="color:red;">所谓的memory order，其实就是限制编译器以及CPU对单线程当中的指令执行顺序进行重排的程度（此外还包括对cache的控制方法）</mark>。这种限制，决定了以atom操作为基准点（边界），对其之前的内存访问命令，以及之后的内存访问命令，能够在多大的范围内自由重排（或者反过来，需要施加多大的保序限制）。从而形成了**6种模式。它本身与多线程无关，是限制的单一线程当中指令执行顺序。**但是（合理的）指令执行顺序的重排在单线程环境下不会造成逻辑错误而在多线程环境下会，所以这个问题的**目的是为了解决多线程环境下出现的问题**。
